[
  {
    "concept_name": "volatility_regime",
    "task_type": "classification",
    "accuracy": 0.9545449438202247,
    "accuracy_std": 0.0032244464919042207,
    "baseline_accuracy": 0.5,
    "p_value": 0.000999000999000999,
    "is_significant": true,
    "cv_scores": [
      0.9525593008739076,
      0.951310861423221,
      0.9600499375780275,
      0.9563046192259675,
      0.9525
    ]
  },
  {
    "concept_name": "duration_bucket",
    "task_type": "classification",
    "accuracy": 0.9045961298377028,
    "accuracy_std": 0.011533889399957618,
    "baseline_accuracy": 0.5037462537462537,
    "p_value": 0.000999000999000999,
    "is_significant": true,
    "cv_scores": [
      0.920099875156055,
      0.8901373283395755,
      0.8926342072409488,
      0.9126092384519351,
      0.9075
    ]
  },
  {
    "concept_name": "category",
    "task_type": "classification",
    "accuracy": 0.7100399600399601,
    "accuracy_std": 0.005744255744255744,
    "baseline_accuracy": 0.28121878121878124,
    "p_value": 0.000999000999000999,
    "is_significant": true,
    "cv_scores": [
      0.7157842157842158,
      0.7042957042957043
    ]
  },
  {
    "concept_name": "winning_outcome",
    "task_type": "classification",
    "accuracy": 0.6905558676654182,
    "accuracy_std": 0.01587174468055345,
    "baseline_accuracy": 0.6381118881118881,
    "p_value": 0.000999000999000999,
    "is_significant": true,
    "cv_scores": [
      0.6928838951310862,
      0.682896379525593,
      0.7203495630461922,
      0.6803995006242197,
      0.67625
    ]
  },
  {
    "concept_name": "volume_bucket",
    "task_type": "classification",
    "accuracy": 0.6643330212234707,
    "accuracy_std": 0.014565328696361159,
    "baseline_accuracy": 0.34015984015984013,
    "p_value": 0.000999000999000999,
    "is_significant": true,
    "cv_scores": [
      0.6529338327091136,
      0.6729088639200999,
      0.6529338327091136,
      0.6891385767790262,
      0.65375
    ]
  }
]